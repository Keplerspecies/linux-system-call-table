{"Man page": "<pre><br><span class=\"headline\">SCHED_SETAFFINITY(2)      Linux Programmer's Manual     SCHED_SETAFFINITY(2)</span><br></pre><br><h2>NAME  </h2><pre><br>       sched_setaffinity,  sched_getaffinity  -  set  and get a thread's CPU<br>       affinity mask<br></pre><br><h2>SYNOPSIS  </h2><pre><br>       <b>#define _GNU_SOURCE             </b>/* See feature_test_macros(7) */<br>       <b>#include &lt;sched.h&gt;</b><br><br>       <b>int sched_setaffinity(pid_t </b><i>pid</i><b>, size_t </b><i>cpusetsize</i><b>,</b><br>                             <b>const cpu_set_t *</b><i>mask</i><b>);</b><br><br>       <b>int sched_getaffinity(pid_t </b><i>pid</i><b>, size_t </b><i>cpusetsize</i><b>,</b><br>                             <b>cpu_set_t *</b><i>mask</i><b>);</b><br></pre><br><h2>DESCRIPTION  </h2><pre><br>       A thread's CPU affinity mask determines the set of CPUs on which it<br>       is eligible to run.  On a multiprocessor system, setting the CPU<br>       affinity mask can be used to obtain performance benefits.  For<br>       example, by dedicating one CPU to a particular thread (i.e., setting<br>       the affinity mask of that thread to specify a single CPU, and setting<br>       the affinity mask of all other threads to exclude that CPU), it is<br>       possible to ensure maximum execution speed for that thread.<br>       Restricting a thread to run on a single CPU also avoids the<br>       performance cost caused by the cache invalidation that occurs when a<br>       thread ceases to execute on one CPU and then recommences execution on<br>       a different CPU.<br><br>       A CPU affinity mask is represented by the <i>cpu_set_t</i> structure, a \"CPU<br>       set\", pointed to by <i>mask</i>.  A set of macros for manipulating CPU sets<br>       is described in CPU_SET(3).<br><br>       <b>sched_setaffinity</b>() sets the CPU affinity mask of the thread whose ID<br>       is <i>pid</i> to the value specified by <i>mask</i>.  If <i>pid</i> is zero, then the<br>       calling thread is used.  The argument <i>cpusetsize</i> is the length (in<br>       bytes) of the data pointed to by <i>mask</i>.  Normally this argument would<br>       be specified as <i>sizeof(cpu_set_t)</i>.<br><br>       If the thread specified by <i>pid</i> is not currently running on one of the<br>       CPUs specified in <i>mask</i>, then that thread is migrated to one of the<br>       CPUs specified in <i>mask</i>.<br><br>       <b>sched_getaffinity</b>() writes the affinity mask of the thread whose ID<br>       is <i>pid</i> into the <i>cpu_set_t</i> structure pointed to by <i>mask</i>.  The<br>       <i>cpusetsize</i> argument specifies the size (in bytes) of <i>mask</i>.  If <i>pid</i> is<br>       zero, then the mask of the calling thread is returned.<br></pre><br><h2>RETURN VALUE  </h2><pre><br>       On success, <b>sched_setaffinity</b>() and <b>sched_getaffinity</b>() return 0.  On<br>       error, -1 is returned, and <i>errno</i> is set appropriately.<br></pre><br><h2>ERRORS  </h2><pre><br>       <b>EFAULT </b>A supplied memory address was invalid.<br><br>       <b>EINVAL </b>The affinity bit mask <i>mask</i> contains no processors that are<br>              currently physically on the system and permitted to the thread<br>              according to any restrictions that may be imposed by the<br>              \"cpuset\" mechanism described in cpuset(7).<br><br>       <b>EINVAL </b>(<b>sched_getaffinity</b>() and, in kernels before 2.6.9,<br>              <b>sched_setaffinity</b>()) <i>cpusetsize</i> is smaller than the size of<br>              the affinity mask used by the kernel.<br><br>       <b>EPERM  </b>(<b>sched_setaffinity</b>()) The calling thread does not have<br>              appropriate privileges.  The caller needs an effective user ID<br>              equal to the real user ID or effective user ID of the thread<br>              identified by <i>pid</i>, or it must possess the <b>CAP_SYS_NICE</b><br>              capability.<br><br>       <b>ESRCH  </b>The thread whose ID is <i>pid</i> could not be found.<br></pre><br><h2>VERSIONS  </h2><pre><br>       The CPU affinity system calls were introduced in Linux kernel 2.5.8.<br>       The system call wrappers were introduced in glibc 2.3.  Initially,<br>       the glibc interfaces included a <i>cpusetsize</i> argument, typed as<br>       <i>unsigned int</i>.  In glibc 2.3.3, the <i>cpusetsize</i> argument was removed,<br>       but was then restored in glibc 2.3.4, with type <i>size_t</i>.<br></pre><br><h2>CONFORMING TO  </h2><pre><br>       These system calls are Linux-specific.<br></pre><br><h2>NOTES  </h2><pre><br>       After a call to <b>sched_setaffinity</b>(), the set of CPUs on which the<br>       thread will actually run is the intersection of the set specified in<br>       the <i>mask</i> argument and the set of CPUs actually present on the system.<br>       The system may further restrict the set of CPUs on which the thread<br>       runs if the \"cpuset\" mechanism described in cpuset(7) is being used.<br>       These restrictions on the actual set of CPUs on which the thread will<br>       run are silently imposed by the kernel.<br><br>       There are various ways of determining the number of CPUs available on<br>       the system, including: inspecting the contents of <i>/proc/cpuinfo</i>;<br>       using sysconf(3) to obtain the values of the <b>_SC_NPROCESSORS_CONF </b>and<br>       <b>_SC_NPROCESSORS_ONLN </b>parameters; and inspecting the list CPU<br>       directories under <i>/sys/devices/system/cpu/</i>.<br><br>       sched(7) has a description of the Linux scheduling scheme.<br><br>       The affinity mask is a per-thread attribute that can be adjusted<br>       independently for each of the threads in a thread group.  The value<br>       returned from a call to gettid(2) can be passed in the argument <i>pid</i>.<br>       Specifying <i>pid</i> as 0 will set the attribute for the calling thread,<br>       and passing the value returned from a call to getpid(2) will set the<br>       attribute for the main thread of the thread group.  (If you are using<br>       the POSIX threads API, then use pthread_setaffinity_np(3) instead of<br>       <b>sched_setaffinity</b>().)<br><br>       The <i>isolcpus</i> boot option can be used to isolate one or more CPUs at<br>       boot time, so that no processes are scheduled onto those CPUs.<br>       Following the use of this boot option, the only way to schedule<br>       processes onto the isolated CPUs is via <b>sched_setaffinity</b>() or the<br>       cpuset(7) mechanism.  For further information, see the kernel source<br>       file <i>Documentation/kernel-parameters.txt</i>.  As noted in that file,<br>       <i>isolcpus</i> is the preferred mechanism of isolating CPUs (versus the<br>       alternative of manually setting the CPU affinity of all processes on<br>       the system).<br><br>       A child created via fork(2) inherits its parent's CPU affinity mask.<br>       The affinity mask is preserved across an execve(2).<br><br>   <b>C library/kernel differences</b><br>       This manual page describes the glibc interface for the CPU affinity<br>       calls.  The actual system call interface is slightly different, with<br>       the <i>mask</i> being typed as <i>unsigned long *</i>, reflecting the fact that the<br>       underlying implementation of CPU sets is a simple bit mask.  On<br>       success, the raw <b>sched_getaffinity</b>() system call returns the size (in<br>       bytes) of the <i>cpumask_t</i> data type that is used internally by the<br>       kernel to represent the CPU set bit mask.<br><br>   <b>Handling systems with large CPU affinity masks</b><br>       The underlying system calls (which represent CPU masks as bit masks<br>       of type <i>unsigned long *</i>) impose no restriction on the size of the CPU<br>       mask.  However, the <i>cpu_set_t</i> data type used by glibc has a fixed<br>       size of 128 bytes, meaning that the maximum CPU number that can be<br>       represented is 1023.  If the kernel CPU affinity mask is larger than<br>       1024, then calls of the form:<br><br>           sched_getaffinity(pid, sizeof(cpu_set_t), &amp;mask);<br><br>       will fail with the error <b>EINVAL</b>, the error produced by the underlying<br>       system call for the case where the <i>mask</i> size specified in <i>cpusetsize</i><br>       is smaller than the size of the affinity mask used by the kernel.<br>       (Depending on the system CPU topology, the kernel affinity mask can<br>       be substantially larger than the number of active CPUs in the<br>       system.)<br><br>       When working on systems with large kernel CPU affinity masks, one<br>       must dynamically allocate the <i>mask</i> argument.  Currently, the only way<br>       to do this is by probing for the size of the required mask using<br>       <b>sched_getaffinity</b>() calls with increasing mask sizes (until the call<br>       does not fail with the error <b>EINVAL</b>).<br></pre><br><h2>EXAMPLE  </h2><pre><br>       The program below creates a child process.  The parent and child then<br>       each assign themselves to a specified CPU and execute identical loops<br>       that consume some CPU time.  Before terminating, the parent waits for<br>       the child to complete.  The program takes three command-line<br>       arguments: the CPU number for the parent, the CPU number for the<br>       child, and the number of loop iterations that both processes should<br>       perform.<br><br>       As the sample runs below demonstrate, the amount of real and CPU time<br>       consumed when running the program will depend on intra-core caching<br>       effects and whether the processes are using the same CPU.<br><br>       We first employ lscpu(1) to determine that this (x86) system has two<br>       cores, each with two CPUs:<br><br>           $ <b>lscpu | grep -i 'core.*:|socket'</b><br>           Thread(s) per core:    2<br>           Core(s) per socket:    2<br>           Socket(s):             1<br><br>       We then time the operation of the example program for three cases:<br>       both processes running on the same CPU; both processes running on<br>       different CPUs on the same core; and both processes running on<br>       different CPUs on different cores.<br><br>           $ <b>time -p ./a.out 0 0 100000000</b><br>           real 14.75<br>           user 3.02<br>           sys 11.73<br>           $ <b>time -p ./a.out 0 1 100000000</b><br>           real 11.52<br>           user 3.98<br>           sys 19.06<br>           $ <b>time -p ./a.out 0 3 100000000</b><br>           real 7.89<br>           user 3.29<br>           sys 12.07<br><br>   <b>Program source</b><br><br>       #define _GNU_SOURCE<br>       #include &lt;sched.h&gt;<br>       #include &lt;stdio.h&gt;<br>       #include &lt;stdlib.h&gt;<br>       #include &lt;unistd.h&gt;<br>       #include &lt;sys/wait.h&gt;<br><br>       #define errExit(msg)    do { perror(msg); exit(EXIT_FAILURE); \\<br>                               } while (0)<br><br>       int<br>       main(int argc, char *argv[])<br>       {<br>           cpu_set_t set;<br>           int parentCPU, childCPU;<br>           int nloops, j;<br><br>           if (argc != 4) {<br>               fprintf(stderr, \"Usage: %s parent-cpu child-cpu num-loops\\n\",<br>                       argv[0]);<br>               exit(EXIT_FAILURE);<br>           }<br><br>           parentCPU = atoi(argv[1]);<br>           childCPU = atoi(argv[2]);<br>           nloops = atoi(argv[3]);<br><br>           CPU_ZERO(&amp;set);<br><br>           switch (fork()) {<br>           case -1:            /* Error */<br>               errExit(\"fork\");<br><br>           case 0:             /* Child */<br>               CPU_SET(childCPU, &amp;set);<br><br>               if (sched_setaffinity(getpid(), sizeof(set), &amp;set) == -1)<br>                   errExit(\"sched_setaffinity\");<br><br>               for (j = 0; j &lt; nloops; j++)<br>                   getppid();<br><br>               exit(EXIT_SUCCESS);<br><br>           default:            /* Parent */<br>               CPU_SET(parentCPU, &amp;set);<br><br>               if (sched_setaffinity(getpid(), sizeof(set), &amp;set) == -1)<br>                   errExit(\"sched_setaffinity\");<br><br>               for (j = 0; j &lt; nloops; j++)<br>                   getppid();<br><br>               wait(NULL);     /* Wait for child to terminate */<br>               exit(EXIT_SUCCESS);<br>           }<br>       }<br></pre><br><h2>SEE ALSO  </h2><pre><br>       lscpu(1), nproc(1), taskset(1), clone(2), getcpu(2), getpriority(2),<br>       gettid(2), nice(2), sched_get_priority_max(2),<br>       sched_get_priority_min(2), sched_getscheduler(2),<br>       sched_setscheduler(2), setpriority(2), CPU_SET(3),<br>       pthread_setaffinity_np(3), sched_getcpu(3), capabilities(7),<br>       cpuset(7), sched(7)<br></pre><br><h2>COLOPHON  </h2><pre><br>       This page is part of release 4.02 of the Linux <i>man-pages</i> project.  A<br>       description of the project, information about reporting bugs, and the<br>       latest version of this page, can be found at<br>       http://www.kernel.org/doc/man-pages/.<br><br><span class=\"footline\">Linux                            2015-07-23             SCHED_SETAFFINITY(2)</span><br></pre><br>"}